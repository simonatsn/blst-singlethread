//!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
// DO NOT EDIT THIS FILE!!
// The file is generated from *.tgo by generate.py
//!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
/*
 * Copyright Supranational LLC
 * Licensed under the Apache License, Version 2.0, see LICENSE for details.
 * SPDX-License-Identifier: Apache-2.0
 */

package blst

// #cgo CFLAGS: -I${SRCDIR}/.. -I${SRCDIR}/../../build -I${SRCDIR}/../../src -D__BLST_CGO__ -march=native -mno-avx
// #include "blst.h"
import "C"
import (
	"fmt"
	"runtime"
	"sync/atomic"
)

const BLST_SCALAR_BYTES = 256 / 8
const BLST_SCALAR_LIMBS = 256 / 64
const BLST_FP_BYTES = 384 / 8
const BLST_FP_LIMBS = 384 / 64
const BLST_P1_COMPRESS_BYTES = BLST_FP_BYTES
const BLST_P1_SERIALIZE_BYTES = BLST_FP_BYTES * 2
const BLST_P2_COMPRESS_BYTES = BLST_FP_BYTES * 2
const BLST_P2_SERIALIZE_BYTES = BLST_FP_BYTES * 4

type Scalar = C.blst_scalar
type Fp = C.blst_fp
type Fp2 = C.blst_fp2
type Fp6 = C.blst_fp6
type Fp12 = C.blst_fp12
type P1 = C.blst_p1
type P2 = C.blst_p2
type P1Affine = C.blst_p1_affine
type P2Affine = C.blst_p2_affine
type Message = []byte
type Pairing = []uint64
type SecretKey = Scalar

//
// Secret key
//
func KeyGen(ikm []byte, optional ...[]byte) *SecretKey {
	var sk SecretKey
	var info []byte
	var infoP *C.byte
	if len(optional) > 0 {
		info = optional[0]
		infoP = (*C.byte)(&info[0])
	}
	if len(ikm) < 32 {
		return nil
	}
	C.blst_keygen(&sk, (*C.byte)(&ikm[0]), C.size_t(len(ikm)),
		infoP, C.size_t(len(info)))
	return &sk
}

//
// Pairing
//
func PairingCtx() Pairing {
	ctx := make([]uint64, C.blst_pairing_sizeof()/8)
	C.blst_pairing_init((*C.blst_pairing)(&ctx[0]))
	return ctx
}

func PairingAggregatePkInG1(ctx Pairing, PK *P1Affine, sig *P2Affine,
	hash_or_encode bool, msg []byte, optional ...[]byte) int {
	var DST []byte
	var uDST *C.byte
	if len(optional) > 0 {
		DST = optional[0]
		uDST = (*C.byte)(&DST[0])
	}
	var aug []byte
	var uaug *C.byte
	if len(optional) > 1 {
		aug = optional[1]
		if aug != nil {
			uaug = (*C.byte)(&aug[0])
		}
	}
	var umsg *C.byte
	if msg != nil {
		umsg = (*C.byte)(&msg[0])
	}

	r := C.blst_pairing_aggregate_pk_in_g1((*C.blst_pairing)(&ctx[0]),
		PK, sig, C.bool(hash_or_encode),
		umsg, C.size_t(len(msg)),
		uDST, C.size_t(len(DST)),
		uaug, C.size_t(len(aug)))

	return int(r)
}

func PairingAggregatePkInG2(ctx Pairing, PK *P2Affine, sig *P1Affine,
	hash_or_encode bool, msg []byte, optional ...[]byte) int {
	var DST []byte
	var uDST *C.byte
	if len(optional) > 0 {
		DST = optional[0]
		uDST = (*C.byte)(&DST[0])
	}
	var aug []byte
	var uaug *C.byte
	if len(optional) > 1 {
		aug = optional[1]
		if aug != nil {
			uaug = (*C.byte)(&aug[0])
		}
	}

	r := C.blst_pairing_aggregate_pk_in_g2((*C.blst_pairing)(&ctx[0]),
		PK, sig, C.bool(hash_or_encode),
		(*C.byte)(&msg[0]), C.size_t(len(msg)),
		uDST, C.size_t(len(DST)),
		uaug, C.size_t(len(aug)))

	return int(r)
}

func PairingCommit(ctx Pairing) {
	C.blst_pairing_commit((*C.blst_pairing)(&ctx[0]))
}

func PairingMerge(ctx Pairing, ctx1 Pairing) int {
	r := C.blst_pairing_merge((*C.blst_pairing)(&ctx[0]),
		(*C.blst_pairing)(&ctx1[0]))
	return int(r)
}

func PairingFinalVerify(ctx Pairing, optional ...*Fp12) bool {
	var gtsig *Fp12 = nil
	if len(optional) > 0 {
		gtsig = optional[0]
	}
	return bool(C.blst_pairing_finalverify((*C.blst_pairing)(&ctx[0]), gtsig))
}

//
// MIN-PK
//

//
// PublicKey
//

func (pk *P1Affine) From(s *Scalar) *P1Affine {
	C.blst_sk_to_pk2_in_g1(nil, pk, s)
	return pk
}

//
// Sign
//

func (sig *P2Affine) Sign(sk *SecretKey, msg []byte, dst []byte,
	optional ...interface{}) *P2Affine {
	augSingle, aug, useHash, ok := parseOpts(optional...)
	if !ok || len(aug) != 0 {
		return nil
	}

	var q *P2
	if useHash {
		q = HashToG2(msg, dst, augSingle)
	} else {
		q = EncodeToG2(msg, dst, augSingle)
	}
	C.blst_sign_pk2_in_g1(nil, sig, q, sk)
	return sig
}

//
// Signature
//

// Functions to return a signature and public key+augmentation tuple.
// This enables point decompression (if needed) to happen in parallel.
type sigGetterP2 func() *P2Affine
type pkGetterP1 func(i uint32, temp *P1Affine) (*P1Affine, []byte)

// Single verify with decompressed pk
func (sig *P2Affine) Verify(pk *P1Affine, msg Message, dst []byte,
	optional ...interface{}) bool { // useHash bool, aug []byte

	// CLEANUP!!
	// Check for infinities (eth spec)
	var zeroSig P2Affine
	var zeroPk P1Affine
	if pk.Equals(&zeroPk) && sig.Equals(&zeroSig) {
		return true
	}
	// CLEANUP!!

	aug, _, useHash, ok := parseOpts(optional...)
	if !ok {
		return false
	}
	return sig.AggregateVerify([]*P1Affine{pk}, []Message{msg}, dst,
		useHash, [][]byte{aug})
}

// Single verify with compressed pk
// Uses a dummy signature to get the correct type
func (dummy *P2Affine) VerifyCompressed(sig []byte, pk []byte,
	msg Message, dst []byte,
	optional ...bool) bool { // useHash bool, usePksAsAugs bool

	return dummy.AggregateVerifyCompressed(sig, [][]byte{pk},
		[]Message{msg}, dst, optional...)
}

// Aggregate verify with uncompressed signature and public keys
func (sig *P2Affine) AggregateVerify(pks []*P1Affine, msgs []Message,
	dst []byte, optional ...interface{}) bool { // useHash bool, augs [][]byte

	// sanity checks and argument parsing
	if len(pks) != len(msgs) {
		return false
	}
	_, augs, useHash, ok := parseOpts(optional...)
	useAugs := len(augs) != 0
	if !ok || (useAugs && len(augs) != len(msgs)) {
		return false
	}

	sigFn := func() *P2Affine {
		return sig
	}

	pkFn := func(i uint32, _ *P1Affine) (*P1Affine, []byte) {
		if useAugs {
			return pks[i], augs[i]
		} else {
			return pks[i], nil
		}
	}

	return coreAggregateVerifyPkInG1(sigFn, pkFn, msgs, dst, useHash)
}

// Aggregate verify with compressed signature and public keys
// Uses a dummy signature to get the correct type
func (dummy *P2Affine) AggregateVerifyCompressed(sig []byte, pks [][]byte,
	msgs []Message, dst []byte, optional ...bool) bool { // useHash bool, usePksAsAugs bool

	// sanity checks and argument parsing
	if len(pks) != len(msgs) {
		return false
	}
	useHash := true
	if len(optional) > 0 {
		useHash = optional[0]
	}
	usePksAsAugs := false
	if len(optional) > 1 {
		usePksAsAugs = optional[1]
	}

	sigFn := func() *P2Affine {
		sigP := new(P2Affine)
		if sig[0]&0x80 == 0 {
			// Not compressed
			if sigP.Deserialize(sig) == nil {
				return nil
			}
		} else {
			if sigP.Uncompress(sig) == nil {
				return nil
			}
		}
		return sigP
	}
	pkFn := func(i uint32, pk *P1Affine) (*P1Affine, []byte) {
		bytes := pks[i]
		if len(bytes) == 0 {
			return nil, nil
		}
		if bytes[0]&0x80 == 0 {
			// Not compressed
			if pk.Deserialize(bytes) == nil {
				return nil, nil
			}
		} else {
			if pk.Uncompress(bytes) == nil {
				return nil, nil
			}
		}
		if usePksAsAugs {
			return pk, bytes
		}
		return pk, nil
	}
	return coreAggregateVerifyPkInG1(sigFn, pkFn, msgs, dst, useHash)
}

// TODO: check message uniqueness
func coreAggregateVerifyPkInG1(sigFn sigGetterP2, pkFn pkGetterP1,
	msgs []Message, dst []byte, optional ...bool) bool { // useHash

	n := len(msgs)
	if n == 0 {
		return true
	}

	useHash := true
	if len(optional) > 0 {
		useHash = optional[0]
	}
    var temp P1Affine
    pairing := PairingCtx()
	for i := uint32(0); i < uint32(n); i++ {
		curPk, aug := pkFn(i, &temp)
		PairingAggregatePkInG1(pairing, curPk, nil,
			useHash, msgs[i], dst, aug)
	}
    PairingCommit(pairing)

	// Uncompress and check signature
	var gtsig Fp12
	sig := sigFn()

	if sig != nil {
		C.blst_aggregated_in_g2(&gtsig, sig)
	}

	if pairing == nil || sig == nil {
		return false
	}

	return PairingFinalVerify(pairing, &gtsig)
}

func (sig *P2Affine) FastAggregateVerify(pks []*P1Affine, msg Message,
	dst []byte, optional ...interface{}) bool {
	n := len(pks)

	// TODO: return value for length zero?
	if n == 0 {
		return false
	}

	aggregator := new(P1Aggregate).Aggregate(pks)
	if aggregator == nil {
		return false
	}
	pkAff := aggregator.ToAffine()

	// Verify
	return sig.Verify(pkAff, msg, dst, optional...)
}

//
// Aggregate P2
//

type aggGetterP2 func(i uint32, temp *P2Affine) *P2Affine
type P2Aggregate struct {
	v *P2
}

// Aggregate uncompressed elements
func (agg *P2Aggregate) Aggregate(elmts []*P2Affine) *P2Aggregate {
	if len(elmts) == 0 {
		return agg
	}
	getter := func(i uint32, _ *P2Affine) *P2Affine { return elmts[i] }
	if !agg.aggregate(getter, len(elmts)) {
		return nil
	}
	return agg
}

// Aggregate compressed elements
func (agg *P2Aggregate) AggregateCompressed(elmts [][]byte) *P2Aggregate {
	if len(elmts) == 0 {
		return agg
	}
	getter := func(i uint32, p *P2Affine) *P2Affine {
		bytes := elmts[i]
		if len(bytes) == 0 {
			return nil
		}
		if bytes[0]&0x80 == 0 {
			// Not compressed
			if p.Deserialize(bytes) == nil {
				return nil
			}
		} else {
			if p.Uncompress(bytes) == nil {
				return nil
			}
		}
		return p
	}
	if !agg.aggregate(getter, len(elmts)) {
		return nil
	}
	return agg
}

func (agg *P2Aggregate) AddAggregate(other *P2Aggregate) *P2Aggregate {
	if other.v == nil {
		// do nothing
	} else if agg.v == nil {
		agg.v = other.v
	} else {
		C.blst_p2_add(agg.v, agg.v, other.v)
	}
	return agg
}

func (agg *P2Aggregate) Add(elmt *P2Affine) *P2Aggregate {
	if agg.v == nil {
		agg.v = new(P2)
		C.blst_p2_from_affine(agg.v, elmt)
	} else {
		C.blst_p2_add_or_double_affine(agg.v, agg.v, elmt)
	}
	return agg
}

func (agg *P2Aggregate) ToAffine() *P2Affine {
	if agg.v == nil {
		return nil
	}
	return agg.v.ToAffine()
}

func (agg *P2Aggregate) aggregate(getter aggGetterP2, n int) bool {
	if n == 0 {
		return true
	}
	numThreads := runtime.GOMAXPROCS(0)
	if numThreads > n {
		numThreads = n
	}

	valid := int32(1)
	type result struct {
		agg   *P2
		empty bool
	}
	msgs := make(chan result, numThreads)
	curItem := uint32(0)
	for tid := 0; tid < numThreads; tid++ {
		go func() {
			first := true
			var agg P2
			var temp P2Affine
			for atomic.LoadInt32(&valid) > 0 {
				// Get a work item
				work := atomic.AddUint32(&curItem, 1) - 1
				if work >= uint32(n) {
					break
				}

				// Signature validate
				curElmt := getter(work, &temp)
				if curElmt == nil {
					atomic.StoreInt32(&valid, 0)
					break
				}
				if first {
					C.blst_p2_from_affine(&agg, curElmt)
					first = false
				} else {
					C.blst_p2_add_or_double_affine(&agg, &agg, curElmt)
				}
			}
			if first {
				msgs <- result{nil, true}
			} else if atomic.LoadInt32(&valid) > 0 {
				msgs <- result{&agg, false}
			} else {
				msgs <- result{nil, false}
			}
		}()
	}

	// Accumulate the thread results
	first := agg.v == nil
	validLocal := true
	for i := 0; i < numThreads; i++ {
		msg := <-msgs
		if !validLocal || msg.empty {
			// do nothing
		} else if msg.agg == nil {
			validLocal = false
			// This should be unnecessary but seems safer
			atomic.StoreInt32(&valid, 0)
		} else {
			if first {
				agg.v = msg.agg
				first = false
			} else {
				C.blst_p2_add(agg.v, agg.v, msg.agg)
			}
		}
	}
	if atomic.LoadInt32(&valid) == 0 {
		agg.v = nil
		return false
	}
	return true
}

//
// MIN-SIG
//

//
// PublicKey
//

func (pk *P2Affine) From(s *Scalar) *P2Affine {
	C.blst_sk_to_pk2_in_g2(nil, pk, s)
	return pk
}

//
// Sign
//

func (sig *P1Affine) Sign(sk *SecretKey, msg []byte, dst []byte,
	optional ...interface{}) *P1Affine {
	augSingle, aug, useHash, ok := parseOpts(optional...)
	if !ok || len(aug) != 0 {
		return nil
	}

	var q *P1
	if useHash {
		q = HashToG1(msg, dst, augSingle)
	} else {
		q = EncodeToG1(msg, dst, augSingle)
	}
	C.blst_sign_pk2_in_g2(nil, sig, q, sk)
	return sig
}

//
// Signature
//

// Functions to return a signature and public key+augmentation tuple.
// This enables point decompression (if needed) to happen in parallel.
type sigGetterP1 func() *P1Affine
type pkGetterP2 func(i uint32, temp *P2Affine) (*P2Affine, []byte)

// Single verify with decompressed pk
func (sig *P1Affine) Verify(pk *P2Affine, msg Message, dst []byte,
	optional ...interface{}) bool { // useHash bool, aug []byte

	// CLEANUP!!
	// Check for infinities (eth spec)
	var zeroSig P1Affine
	var zeroPk P2Affine
	if pk.Equals(&zeroPk) && sig.Equals(&zeroSig) {
		return true
	}
	// CLEANUP!!

	aug, _, useHash, ok := parseOpts(optional...)
	if !ok {
		return false
	}
	return sig.AggregateVerify([]*P2Affine{pk}, []Message{msg}, dst,
		useHash, [][]byte{aug})
}

// Single verify with compressed pk
// Uses a dummy signature to get the correct type
func (dummy *P1Affine) VerifyCompressed(sig []byte, pk []byte,
	msg Message, dst []byte,
	optional ...bool) bool { // useHash bool, usePksAsAugs bool

	return dummy.AggregateVerifyCompressed(sig, [][]byte{pk},
		[]Message{msg}, dst, optional...)
}

// Aggregate verify with uncompressed signature and public keys
func (sig *P1Affine) AggregateVerify(pks []*P2Affine, msgs []Message,
	dst []byte,
	optional ...interface{}) bool { // useHash bool, augs [][]byte

	// sanity checks and argument parsing
	if len(pks) != len(msgs) {
		return false
	}
	_, augs, useHash, ok := parseOpts(optional...)
	useAugs := len(augs) != 0
	if !ok || (useAugs && len(augs) != len(msgs)) {
		return false
	}

	sigFn := func() *P1Affine {
		return sig
	}

	pkFn := func(i uint32, _ *P2Affine) (*P2Affine, []byte) {
		if useAugs {
			return pks[i], augs[i]
		} else {
			return pks[i], nil
		}
	}

	return coreAggregateVerifyPkInG2(sigFn, pkFn, msgs, dst, useHash)
}

// Aggregate verify with compressed signature and public keys
// Uses a dummy signature to get the correct type
func (dummy *P1Affine) AggregateVerifyCompressed(sig []byte, pks [][]byte,
	msgs []Message, dst []byte,
	optional ...bool) bool { // useHash bool, usePksAsAugs bool

	// sanity checks and argument parsing
	if len(pks) != len(msgs) {
		return false
	}
	useHash := true
	if len(optional) > 0 {
		useHash = optional[0]
	}
	usePksAsAugs := false
	if len(optional) > 1 {
		usePksAsAugs = optional[1]
	}

	sigFn := func() *P1Affine {
		sigP := new(P1Affine)
		if sig[0]&0x80 == 0 {
			// Not compressed
			if sigP.Deserialize(sig) == nil {
				return nil
			}
		} else {
			if sigP.Uncompress(sig) == nil {
				return nil
			}
		}
		return sigP
	}
	pkFn := func(i uint32, pk *P2Affine) (*P2Affine, []byte) {
		bytes := pks[i]
		if len(bytes) == 0 {
			return nil, nil
		}
		if bytes[0]&0x80 == 0 {
			// Not compressed
			if pk.Deserialize(bytes) == nil {
				return nil, nil
			}
		} else {
			if pk.Uncompress(bytes) == nil {
				return nil, nil
			}
		}
		if usePksAsAugs {
			return pk, bytes
		}
		return pk, nil
	}
	return coreAggregateVerifyPkInG2(sigFn, pkFn, msgs, dst, useHash)
}

// TODO: check message uniqueness
func coreAggregateVerifyPkInG2(sigFn sigGetterP1, pkFn pkGetterP2,
	msgs []Message, dst []byte,
	optional ...bool) bool { // useHash

	n := len(msgs)
	if n == 0 {
		return true
	}

	useHash := true
	if len(optional) > 0 {
		useHash = optional[0]
	}

	numThreads := runtime.GOMAXPROCS(0)
	if numThreads > n {
		numThreads = n
	}
	// Each thread will determine next message to process by atomically
	// incrementing curItem, process corresponding pk,msg[,aug] tuple and
	// repeat until n is exceeded.  The resulting accumulations will be
	// fed into the msgsCh channel.
	msgsCh := make(chan Pairing, numThreads)
	valid := int32(1)
	curItem := uint32(0)
	for tid := 0; tid < numThreads; tid++ {
		go func() {
			pairing := PairingCtx()
			var temp P2Affine
			for atomic.LoadInt32(&valid) > 0 {
				// Get a work item
				work := atomic.AddUint32(&curItem, 1) - 1
				if work >= uint32(n) {
					break
				}

				// pull Public Key and augmentation blob
				curPk, aug := pkFn(work, &temp)
				if curPk == nil {
					atomic.StoreInt32(&valid, 0)
					break
				}

				// Pairing and accumulate
				// TODO: delay subgroup check until miller loop by default
				PairingAggregatePkInG2(pairing, curPk, nil,
					useHash, msgs[work], dst, aug)

				// application might have some async work to do
				runtime.Gosched()
			}
			if atomic.LoadInt32(&valid) > 0 {
				PairingCommit(pairing)
				msgsCh <- pairing
			} else {
				msgsCh <- nil
			}
		}()
	}

	// Uncompress and check signature
	var gtsig Fp12
	sig := sigFn()
	if sig == nil {
		atomic.StoreInt32(&valid, 0)
	} else {
		C.blst_aggregated_in_g1(&gtsig, sig)
	}

	// Accumulate the thread results
	var pairings Pairing
	for i := 0; i < numThreads; i++ {
		msg := <-msgsCh
		if msg != nil {
			if pairings == nil {
				pairings = msg
			} else {
				PairingMerge(pairings, msg)
			}
		}
	}
	if atomic.LoadInt32(&valid) == 0 || pairings == nil {
		return false
	}

	return PairingFinalVerify(pairings, &gtsig)
}

func (sig *P1Affine) FastAggregateVerify(pks []*P2Affine, msg Message,
	dst []byte, optional ...interface{}) bool {
	n := len(pks)

	// TODO: return value for length zero?
	if n == 0 {
		return false
	}

	aggregator := new(P2Aggregate).Aggregate(pks)
	if aggregator == nil {
		return false
	}
	pkAff := aggregator.ToAffine()

	// Verify
	return sig.Verify(pkAff, msg, dst, optional...)
}

//
// Aggregate P1
//

type aggGetterP1 func(i uint32, temp *P1Affine) *P1Affine
type P1Aggregate struct {
	v *P1
}

// Aggregate uncompressed elements
func (agg *P1Aggregate) Aggregate(elmts []*P1Affine) *P1Aggregate {
	if len(elmts) == 0 {
		return agg
	}
	getter := func(i uint32, _ *P1Affine) *P1Affine { return elmts[i] }
	if !agg.aggregate(getter, len(elmts)) {
		return nil
	}
	return agg
}

// Aggregate compressed elements
func (agg *P1Aggregate) AggregateCompressed(elmts [][]byte) *P1Aggregate {
	if len(elmts) == 0 {
		return agg
	}
	getter := func(i uint32, p *P1Affine) *P1Affine {
		bytes := elmts[i]
		if len(bytes) == 0 {
			return nil
		}
		if bytes[0]&0x80 == 0 {
			// Not compressed
			if p.Deserialize(bytes) == nil {
				return nil
			}
		} else {
			if p.Uncompress(bytes) == nil {
				return nil
			}
		}
		return p
	}
	if !agg.aggregate(getter, len(elmts)) {
		return nil
	}
	return agg
}

func (agg *P1Aggregate) AddAggregate(other *P1Aggregate) *P1Aggregate {
	if other.v == nil {
		// do nothing
	} else if agg.v == nil {
		agg.v = other.v
	} else {
		C.blst_p1_add(agg.v, agg.v, other.v)
	}
	return agg
}

func (agg *P1Aggregate) Add(elmt *P1Affine) *P1Aggregate {
	if agg.v == nil {
		agg.v = new(P1)
		C.blst_p1_from_affine(agg.v, elmt)
	} else {
		C.blst_p1_add_or_double_affine(agg.v, agg.v, elmt)
	}
	return agg
}

func (agg *P1Aggregate) ToAffine() *P1Affine {
	if agg.v == nil {
		return nil
	}
	return agg.v.ToAffine()
}

func (agg *P1Aggregate) aggregate(getter aggGetterP1, n int) bool {
	if n == 0 {
		return true
	}
	numThreads := runtime.GOMAXPROCS(0)
	if numThreads > n {
		numThreads = n
	}

	valid := int32(1)
	type result struct {
		agg   *P1
		empty bool
	}
	msgs := make(chan result, numThreads)
	curItem := uint32(0)
	for tid := 0; tid < numThreads; tid++ {
		go func() {
			first := true
			var agg P1
			var temp P1Affine
			for atomic.LoadInt32(&valid) > 0 {
				// Get a work item
				work := atomic.AddUint32(&curItem, 1) - 1
				if work >= uint32(n) {
					break
				}

				// Signature validate
				curElmt := getter(work, &temp)
				if curElmt == nil {
					atomic.StoreInt32(&valid, 0)
					break
				}
				if first {
					C.blst_p1_from_affine(&agg, curElmt)
					first = false
				} else {
					C.blst_p1_add_or_double_affine(&agg, &agg, curElmt)
				}
			}
			if first {
				msgs <- result{nil, true}
			} else if atomic.LoadInt32(&valid) > 0 {
				msgs <- result{&agg, false}
			} else {
				msgs <- result{nil, false}
			}
		}()
	}

	// Accumulate the thread results
	first := agg.v == nil
	validLocal := true
	for i := 0; i < numThreads; i++ {
		msg := <-msgs
		if !validLocal || msg.empty {
			// do nothing
		} else if msg.agg == nil {
			validLocal = false
			// This should be unnecessary but seems safer
			atomic.StoreInt32(&valid, 0)
		} else {
			if first {
				agg.v = msg.agg
				first = false
			} else {
				C.blst_p1_add(agg.v, agg.v, msg.agg)
			}
		}
	}
	if atomic.LoadInt32(&valid) == 0 {
		agg.v = nil
		return false
	}
	return true
}

//
// Serialization/Deserialization.
//

// P1 Serdes
func (p1 *P1Affine) Serialize() []byte {
	var out [BLST_P1_SERIALIZE_BYTES]byte
	C.blst_p1_affine_serialize((*C.byte)(&out[0]), p1)
	return out[:]
}

func (p1 *P1Affine) Deserialize(in []byte) *P1Affine {
	if len(in) != BLST_P1_SERIALIZE_BYTES {
		return nil
	}
	if C.blst_p1_deserialize(p1,
		(*C.byte)(&in[0])) != C.BLST_SUCCESS {
		return nil
	}
	// CLEANUP!!
	// Check for infinities (eth spec)
	var zero P1Affine
	if p1.Equals(&zero) {
		return p1
	}
	// CLEANUP!!

	if !bool(C.blst_p1_affine_in_g1(p1)) {
		return nil
	}
	return p1
}
func (p1 *P1Affine) Compress() []byte {
	var out [BLST_P1_COMPRESS_BYTES]byte
	C.blst_p1_affine_compress((*C.byte)(&out[0]), p1)
	return out[:]
}

func (p1 *P1Affine) Uncompress(in []byte) *P1Affine {
	if len(in) != BLST_P1_COMPRESS_BYTES {
		return nil
	}
	if C.blst_p1_uncompress(p1,
		(*C.byte)(&in[0])) != C.BLST_SUCCESS {
		return nil
	}
	// CLEANUP!!
	// Check for infinities (eth spec)
	var zero P1Affine
	if p1.Equals(&zero) {
		return p1
	}
	// CLEANUP!!

	if !bool(C.blst_p1_affine_in_g1(p1)) {
		return nil
	}
	return p1
}
func (p1 *P1) Serialize() []byte {
	var out [BLST_P1_SERIALIZE_BYTES]byte
	C.blst_p1_serialize((*C.byte)(&out[0]), p1)
	return out[:]
}
func (p1 *P1) Compress() []byte {
	var out [BLST_P1_COMPRESS_BYTES]byte
	C.blst_p1_compress((*C.byte)(&out[0]), p1)
	return out[:]
}

//
// Affine
//

func (p *P1) ToAffine() *P1Affine {
	var pa P1Affine
	C.blst_p1_to_affine(&pa, p)
	return &pa
}

//
// Hash
//
func HashToG1(msg []byte, dst []byte, optional ...[]byte) *P1 {
	var q P1

	var aug []byte
	var uaug *C.byte
	if len(optional) > 0 {
		aug = optional[0]
		if len(aug) > 0 {
			uaug = (*C.byte)(&aug[0])
		}
	}

	C.blst_hash_to_g1(&q,
		(*C.byte)(&msg[0]), C.size_t(len(msg)),
		(*C.byte)(&dst[0]), C.size_t(len(dst)),
		uaug, C.size_t(len(aug)))
	return &q
}

func EncodeToG1(msg []byte, dst []byte, optional ...[]byte) *P1 {
	var q P1

	var aug []byte
	var uaug *C.byte
	if len(optional) > 0 {
		aug = optional[0]
		if len(aug) > 0 {
			uaug = (*C.byte)(&aug[0])
		}
	}

	C.blst_encode_to_g1(&q,
		(*C.byte)(&msg[0]), C.size_t(len(msg)),
		(*C.byte)(&dst[0]), C.size_t(len(dst)),
		uaug, C.size_t(len(aug)))
	return &q
}

//
// Serialization/Deserialization.
//

// P2 Serdes
func (p2 *P2Affine) Serialize() []byte {
	var out [BLST_P2_SERIALIZE_BYTES]byte
	C.blst_p2_affine_serialize((*C.byte)(&out[0]), p2)
	return out[:]
}

func (p2 *P2Affine) Deserialize(in []byte) *P2Affine {
	if len(in) != BLST_P2_SERIALIZE_BYTES {
		return nil
	}
	if C.blst_p2_deserialize(p2,
		(*C.byte)(&in[0])) != C.BLST_SUCCESS {
		return nil
	}
	// CLEANUP!!
	// Check for infinities (eth spec)
	var zero P2Affine
	if p2.Equals(&zero) {
		return p2
	}
	// CLEANUP!!

	if !bool(C.blst_p2_affine_in_g2(p2)) {
		return nil
	}
	return p2
}
func (p2 *P2Affine) Compress() []byte {
	var out [BLST_P2_COMPRESS_BYTES]byte
	C.blst_p2_affine_compress((*C.byte)(&out[0]), p2)
	return out[:]
}

func (p2 *P2Affine) Uncompress(in []byte) *P2Affine {
	if len(in) != BLST_P2_COMPRESS_BYTES {
		return nil
	}
	if C.blst_p2_uncompress(p2,
		(*C.byte)(&in[0])) != C.BLST_SUCCESS {
		return nil
	}
	// CLEANUP!!
	// Check for infinities (eth spec)
	var zero P2Affine
	if p2.Equals(&zero) {
		return p2
	}
	// CLEANUP!!

	if !bool(C.blst_p2_affine_in_g2(p2)) {
		return nil
	}
	return p2
}
func (p2 *P2) Serialize() []byte {
	var out [BLST_P2_SERIALIZE_BYTES]byte
	C.blst_p2_serialize((*C.byte)(&out[0]), p2)
	return out[:]
}
func (p2 *P2) Compress() []byte {
	var out [BLST_P2_COMPRESS_BYTES]byte
	C.blst_p2_compress((*C.byte)(&out[0]), p2)
	return out[:]
}

//
// Affine
//

func (p *P2) ToAffine() *P2Affine {
	var pa P2Affine
	C.blst_p2_to_affine(&pa, p)
	return &pa
}

//
// Hash
//
func HashToG2(msg []byte, dst []byte, optional ...[]byte) *P2 {
	var q P2

	var aug []byte
	var uaug *C.byte
	if len(optional) > 0 {
		aug = optional[0]
		if len(aug) > 0 {
			uaug = (*C.byte)(&aug[0])
		}
	}

	C.blst_hash_to_g2(&q,
		(*C.byte)(&msg[0]), C.size_t(len(msg)),
		(*C.byte)(&dst[0]), C.size_t(len(dst)),
		uaug, C.size_t(len(aug)))
	return &q
}

func EncodeToG2(msg []byte, dst []byte, optional ...[]byte) *P2 {
	var q P2

	var aug []byte
	var uaug *C.byte
	if len(optional) > 0 {
		aug = optional[0]
		if len(aug) > 0 {
			uaug = (*C.byte)(&aug[0])
		}
	}

	C.blst_encode_to_g2(&q,
		(*C.byte)(&msg[0]), C.size_t(len(msg)),
		(*C.byte)(&dst[0]), C.size_t(len(dst)),
		uaug, C.size_t(len(aug)))
	return &q
}

func parseOpts(optional ...interface{}) ([]byte, [][]byte, bool, bool) {
	var aug [][]byte     // For aggregate verify
	var augSingle []byte // For signing
	useHash := true      // hash (true), encode (false)

	for _, arg := range optional {
		switch v := arg.(type) {
		case []byte:
			augSingle = v
		case [][]byte:
			aug = v
		case bool:
			useHash = v
		default:
			return nil, nil, useHash, false
		}
	}
	return augSingle, aug, useHash, true
}

//
// Serialization/Deserialization.
//

// Scalar serdes
func (s *Scalar) Serialize() []byte {
	var out [BLST_SCALAR_BYTES]byte
	C.blst_bendian_from_scalar((*C.byte)(&out[0]), s)
	return out[:]
}

func (s *Scalar) Deserialize(in []byte) *Scalar {
	if len(in) != BLST_SCALAR_BYTES {
		return nil
	}
	C.blst_scalar_from_bendian(s, (*C.byte)(&in[0]))
	if !C.blst_scalar_fr_check(s) {
		return nil
	}
	return s
}

//
// LEndian
//

func (fr *Scalar) ToLEndian() []byte {
	var arr [BLST_SCALAR_BYTES]byte
	C.blst_lendian_from_scalar((*C.byte)(&arr[0]), fr)
	return arr[:]
}

func (fp *Fp) ToLEndian() []byte {
	var arr [BLST_FP_BYTES]byte
	C.blst_lendian_from_fp((*C.byte)(&arr[0]), fp)
	return arr[:]
}

//
// BEndian
//

func (fr *Scalar) ToBEndian() []byte {
	var arr [BLST_SCALAR_BYTES]byte
	C.blst_bendian_from_scalar((*C.byte)(&arr[0]), fr)
	return arr[:]
}

func (fp *Fp) ToBEndian() []byte {
	var arr [BLST_FP_BYTES]byte
	C.blst_bendian_from_fp((*C.byte)(&arr[0]), fp)
	return arr[:]
}

//
// Printing
//

func PrintBytes(val []byte, name string) {
	fmt.Printf("%s = %02x\n", name, val)
}

func (s *Scalar) Print(name string) {
	arr := s.ToBEndian()
	PrintBytes(arr[:], name)
}

func (p *P1) Print(name string) {
	fmt.Printf("%s:\n", name)
	aff := p.ToAffine()
	arr := aff.x.ToBEndian()
	PrintBytes(arr, "  x")
	arr = aff.y.ToBEndian()
	PrintBytes(arr, "  y")
}

func (f *Fp2) Print(name string) {
	fmt.Printf("%s:\n", name)
	arr := f.fp[0].ToBEndian()
	PrintBytes(arr, "    0")
	arr = f.fp[1].ToBEndian()
	PrintBytes(arr, "    1")
}

func (p *P2) Print(name string) {
	fmt.Printf("%s:\n", name)
	aff := p.ToAffine()
	aff.x.Print("  x")
	aff.y.Print("  y")
}

//
// Equality
//

// TODO: replace with C functions

func (s1 *Scalar) Equals(s2 *Scalar) bool {
	equal := true
	for i := 0; i < BLST_SCALAR_LIMBS; i++ {
		if s1.l[i] != s2.l[i] {
			equal = false
		}
	}
	return equal
}

func (e1 *Fp) Equals(e2 *Fp) bool {
	equal := true
	for i := 0; i < BLST_FP_LIMBS; i++ {
		if e1.l[i] != e2.l[i] {
			equal = false
		}
	}
	return equal
}

func (e1 *Fp2) Equals(e2 *Fp2) bool {
	return (&(e1.fp[0])).Equals(&e2.fp[0]) && (&(e1.fp[1])).Equals(&e2.fp[1])
}

func (e1 *Fp6) Equals(e2 *Fp6) bool {
	return (&(e1.fp2[0])).Equals(&e2.fp2[0]) &&
		(&(e1.fp2[1])).Equals(&e2.fp2[1]) &&
		(&(e1.fp2[2])).Equals(&e2.fp2[2])
}

func (e1 *P1Affine) Equals(e2 *P1Affine) bool {
	return bool(C.blst_p1_affine_is_equal(e1, e2))
}

func (e1 *P2Affine) Equals(e2 *P2Affine) bool {
	return bool(C.blst_p2_affine_is_equal(e1, e2))
}
